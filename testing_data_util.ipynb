{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a6c669-c429-45a0-9794-cff289a35c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a3c576b-9930-4b14-a534-3b73a5ef3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/global/ml4hep/spss/mfong/transfer_learning/delphes_train/\"\n",
    "train_file_names = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3149a61-2e20-4aa9-b9ba-2cf324d01413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_10.h5',\n",
       " 'train_5.h5',\n",
       " 'train_0.h5',\n",
       " 'train_8.h5',\n",
       " 'train_14.h5',\n",
       " 'train_4.h5',\n",
       " 'train_1.h5',\n",
       " 'train_6.h5',\n",
       " 'train_12.h5',\n",
       " 'train_7.h5',\n",
       " 'train_9.h5',\n",
       " 'train_2.h5',\n",
       " 'train_13.h5',\n",
       " 'train_11.h5',\n",
       " 'train_3.h5']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c8b21bc-1d6f-41fc-82ef-83ea9909d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5Dataset(Dataset):\n",
    "    def __init__(self, file_paths, batch_size, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.sample_indices = []  # Store the indices of samples within each file\n",
    "        self.FEATURE_KEYS = ['fjet_clus_eta', 'fjet_clus_phi', 'fjet_clus_pt', 'fjet_clus_E']\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            with h5py.File(file_path, 'r') as file:\n",
    "                num_samples = len(file[self.FEATURE_KEYS[0]])  # 'data' is the dataset name in your HDF5 file\n",
    "                indices = list(range(num_samples))\n",
    "                self.sample_indices.extend([(file_path, idx) for idx in indices])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, sample_idx = self.sample_indices[idx]\n",
    "        \n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            data = file['data'][sample_idx]  # Load a single sample\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bae474dc-747c-4f08-9194-417f1530ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = H5Dataset([train_dir + filename for filename in train_file_names], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39eaa246-fe79-428f-a984-eebaf438a844",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'data' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 22\u001b[0m, in \u001b[0;36mH5Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m file_path, sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_indices[idx]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 22\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[sample_idx]  \u001b[38;5;66;03m# Load a single sample\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     25\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(data)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 357\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:190\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'data' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f72fa81e-2a0d-45ba-bf2c-f430a663a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(train_dir + train_file_names[0], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58372b42-e24b-4a7f-b610-836fc79caef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['fjet_clus_E', 'fjet_clus_eta', 'fjet_clus_phi', 'fjet_clus_pt', 'fjet_eta', 'fjet_m', 'fjet_phi', 'fjet_pt', 'labels', 'training_weights']>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50b30a5f-cf95-4b66-8576-8e773563e87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"fjet_clus_E\": shape (5000000, 200), type \"<f4\">"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"fjet_clus_E\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba6afb4-6a63-44dc-ba78-efc4a013833d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
