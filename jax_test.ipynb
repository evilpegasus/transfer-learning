{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX version 0.4.8\n",
      "Haiku version 0.0.9\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".25\"\n",
    "\n",
    "from typing import NamedTuple\n",
    "import h5py\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import haiku as hk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(8)\n",
    "print(\"JAX version {}\".format(jax.__version__))\n",
    "print(\"Haiku version {}\".format(hk.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jax.device_put(jnp.array([1,2,3,4,5,6,7,8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "f = h5py.File('/clusterfs/ml4hep/mfong/transfer_learning/delphes_train.h5', 'r')\n",
    "f2 = h5py.File('/clusterfs/ml4hep/mfong/transfer_learning/delphes_test.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fjet_clus_E (4000068, 200)\n",
      "fjet_clus_eta (4000068, 200)\n",
      "fjet_clus_phi (4000068, 200)\n",
      "fjet_clus_pt (4000068, 200)\n",
      "fjet_eta (4000068,)\n",
      "fjet_m (4000068,)\n",
      "fjet_phi (4000068,)\n",
      "fjet_pt (4000068,)\n",
      "labels (4000068,)\n"
     ]
    }
   ],
   "source": [
    "feature_keys = ['fjet_clus_eta', 'fjet_clus_phi', 'fjet_clus_pt']\n",
    "for k in f.keys():\n",
    "    print(k, f[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000068, 600)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.concatenate([f[k] for k in feature_keys], axis=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "\n",
    "x = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000068,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = f[\"labels\"][:]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=8)\n",
    "train_batch_size = 64\n",
    "eval_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = jax.tree_map(lambda x: jnp.array(x, jnp.float32), jax.random.split(jax.random.PRNGKey(0), len(x_train)//train_batch_size))\n",
    "train_batches = [(train_batches[i], jnp.array(y_train[i:i+train_batch_size], jnp.int32)) for i in range(0, len(train_batches))]\n",
    "eval_batches = jax.tree_map(lambda x: jnp.array(x, jnp.float32), jax.random.split(jax.random.PRNGKey(1), len(x_test)//eval_batch_size))\n",
    "eval_batches = [(eval_batches[i], jnp.array(y_test[i:i+eval_batch_size], jnp.int32)) for i in range(0, len(eval_batches))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200054, 600)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP starter code\n",
    "https://www.kaggle.com/code/alembcke/titanic-multi-layer-perceptron-using-haiku-jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingState(NamedTuple):\n",
    "    params: hk.Params\n",
    "    # avg_params: hk.Params\n",
    "    opt_state: optax.OptState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_fn(x: jax.Array) -> jax.Array:\n",
    "  \"\"\"Standard MLP network.\"\"\"\n",
    "  mlp = hk.Sequential([\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(64), jax.nn.relu,\n",
    "      hk.Linear(8), jax.nn.relu,\n",
    "      hk.Linear(1),\n",
    "  ])\n",
    "  return mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = hk.without_apply_rng(hk.transform(net_fn))\n",
    "optimiser = optax.adam(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params: hk.Params, features: jnp.ndarray, labels: jnp.ndarray):\n",
    "    \"\"\"Loss function, using Sigmoid Binary Cross Entropy loss.\"\"\"\n",
    "    logits = network.apply(params, features)\n",
    "    return optax.sigmoid_binary_cross_entropy(logits, labels).sum(axis=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def evaluate(params: hk.Params, features: jnp.ndarray, labels: jnp.ndarray):\n",
    "    \"\"\"Checks the accuracy of predictions compared to labels.\"\"\"\n",
    "    logits = network.apply(params, features)\n",
    "    predictions = jnp.around(logits, 0)\n",
    "    return jnp.mean(predictions == labels)\n",
    "\n",
    "@jax.jit\n",
    "def update(state: TrainingState, features: jnp.ndarray, labels: jnp.ndarray) -> TrainingState:\n",
    "    \"\"\"Learning rule (stochastic gradient descent).\"\"\"\n",
    "    grads = jax.grad(loss)(state.params, features, labels)\n",
    "    updates, opt_state = optimiser.update(grads, state.opt_state)\n",
    "    params = optax.apply_updates(state.params, updates)\n",
    "    # Compute avg_params, the exponential moving average of the \"live\" params.\n",
    "    # We use this only for evaluation (cf. https://doi.org/10.1137/0330046).\n",
    "    # avg_params = optax.incremental_update(params, state.avg_params, step_size=0.001)\n",
    "    # return TrainingState(params, avg_params, opt_state)\n",
    "    return TrainingState(params, opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = network.init(jax.random.PRNGKey(seed=8), x[0])\n",
    "initial_opt_state = optimiser.init(initial_params)\n",
    "state = TrainingState(initial_params, initial_opt_state)\n",
    "# state = TrainingState(initial_params, initial_params, initial_opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(hk.experimental.tabulate(network)(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 0, 'accuracy': '0.498'}\n",
      "{'step': 10, 'accuracy': '0.497'}\n",
      "{'step': 20, 'accuracy': '0.501'}\n",
      "{'step': 30, 'accuracy': '0.501'}\n",
      "{'step': 40, 'accuracy': '0.501'}\n",
      "{'step': 50, 'accuracy': '0.501'}\n",
      "{'step': 60, 'accuracy': '0.501'}\n",
      "{'step': 70, 'accuracy': '0.501'}\n",
      "{'step': 80, 'accuracy': '0.501'}\n",
      "{'step': 90, 'accuracy': '0.501'}\n"
     ]
    }
   ],
   "source": [
    "for step in range(100):\n",
    "    if step % 10 == 0:\n",
    "        accuracy = np.array(evaluate(state.params, x[:10000], y[:10000])).item()\n",
    "        print({\"step\": step, \"accuracy\": f\"{accuracy:.3f}\"})\n",
    "\n",
    "    # Do SGD on training examples.\n",
    "    state = update(state, x[:10000], y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
