{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# import haiku as hk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "np.random.seed(8)\n",
    "tf.random.set_seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('/clusterfs/ml4hep/mfong/transfer_learning/delphes_train.h5', 'r')\n",
    "f2 = h5py.File('/clusterfs/ml4hep/mfong/transfer_learning/delphes_test.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fjet_clus_E (4000068, 200)\n",
      "fjet_clus_eta (4000068, 200)\n",
      "fjet_clus_phi (4000068, 200)\n",
      "fjet_clus_pt (4000068, 200)\n",
      "fjet_eta (4000068,)\n",
      "fjet_m (4000068,)\n",
      "fjet_phi (4000068,)\n",
      "fjet_pt (4000068,)\n",
      "labels (4000068,)\n"
     ]
    }
   ],
   "source": [
    "feature_keys = ['fjet_clus_eta', 'fjet_clus_phi', 'fjet_clus_pt']\n",
    "for k in f.keys():\n",
    "    print(k, f[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000068, 600)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.concatenate([f[k] for k in feature_keys], axis=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "\n",
    "x = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000068,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = f[\"labels\"][:]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick logistic regression test\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/mfong/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=8)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_reg = LogisticRegression(random_state=8)\n",
    "logistic_reg.fit(x[:256000], y[:256000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample Acc: 0.77969921875\n",
      "Out of sample Acc: 0.7800078125\n"
     ]
    }
   ],
   "source": [
    "print(\"In sample Acc:\", logistic_reg.score(x[:256000], y[:256000]))\n",
    "print(\"Out of sample Acc:\", logistic_reg.score(x[256000:512000], y[256000:512000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(600,), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_18/kernel:0' shape=(600, 64) dtype=float32, numpy=\n",
       " array([[-0.02558209, -0.03079722,  0.016824  , ..., -0.02682649,\n",
       "          0.08155291,  0.03427844],\n",
       "        [-0.0223344 ,  0.00111546, -0.03407578, ..., -0.0214681 ,\n",
       "         -0.02278921, -0.01171391],\n",
       "        [ 0.04239799, -0.04694584, -0.04062798, ..., -0.06666273,\n",
       "         -0.04073998, -0.03917032],\n",
       "        ...,\n",
       "        [-0.03037461,  0.09354982,  0.08570632, ..., -0.07042781,\n",
       "          0.07279515,  0.00742079],\n",
       "        [ 0.07771151, -0.06429571,  0.06354998, ..., -0.08217992,\n",
       "         -0.03654257,  0.02611994],\n",
       "        [ 0.08519252, -0.07327612, -0.06033182, ..., -0.03859762,\n",
       "          0.05293804, -0.03686836]], dtype=float32)>,\n",
       " <tf.Variable 'dense_18/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_19/kernel:0' shape=(64, 8) dtype=float32, numpy=\n",
       " array([[-0.15091743, -0.12147166, -0.23501731,  0.1506199 ,  0.2678749 ,\n",
       "          0.256321  ,  0.03000215, -0.18006599],\n",
       "        [ 0.17910221,  0.137068  ,  0.19660008,  0.07482263, -0.09259021,\n",
       "         -0.16233654,  0.13264844,  0.15086505],\n",
       "        [ 0.10525203,  0.14147007,  0.19319844, -0.22088861, -0.14480186,\n",
       "         -0.05697383,  0.25761527,  0.03944039],\n",
       "        [ 0.16365874,  0.23434335, -0.2644864 , -0.16279691, -0.19331434,\n",
       "          0.17478192, -0.25744253, -0.2812092 ],\n",
       "        [-0.11381552, -0.07210815, -0.26967737,  0.17897084, -0.05626452,\n",
       "          0.2360642 ,  0.20782608, -0.12961538],\n",
       "        [ 0.13772583, -0.04454243, -0.05346593, -0.28681678,  0.10019866,\n",
       "         -0.09148914,  0.07561755,  0.17729467],\n",
       "        [ 0.05431813,  0.28132045, -0.1069413 , -0.03141856,  0.19059548,\n",
       "         -0.25688654,  0.0660592 ,  0.22565532],\n",
       "        [-0.13327008,  0.23751086,  0.12852663, -0.04268304,  0.02974117,\n",
       "          0.00712207, -0.19911414,  0.01318055],\n",
       "        [ 0.20270091,  0.10423473,  0.2530393 ,  0.25164193, -0.16408086,\n",
       "         -0.18375152, -0.10674989,  0.20065948],\n",
       "        [-0.18175614, -0.07868828, -0.21643904,  0.10541317, -0.06872399,\n",
       "          0.11399633, -0.2672039 ,  0.1536926 ],\n",
       "        [-0.08712815,  0.14884922, -0.00357163,  0.09760317, -0.03776243,\n",
       "          0.24337721,  0.13662732, -0.10877164],\n",
       "        [-0.07614207,  0.17391258, -0.15424259, -0.19629064, -0.02012721,\n",
       "         -0.20986441, -0.2474368 , -0.13242614],\n",
       "        [-0.05707948,  0.24459344,  0.1464296 ,  0.06077251,  0.10532472,\n",
       "         -0.0733455 , -0.18931931, -0.00739703],\n",
       "        [ 0.13551566, -0.28744647, -0.09763318,  0.17546129,  0.059863  ,\n",
       "          0.234429  , -0.02510121, -0.15297455],\n",
       "        [-0.03389803,  0.1480354 , -0.01816773, -0.14293607,  0.17831844,\n",
       "         -0.07134157, -0.0604279 ,  0.07878345],\n",
       "        [-0.21362944, -0.11283427, -0.10557655, -0.14579928,  0.11182749,\n",
       "          0.02813375, -0.09980814, -0.11853929],\n",
       "        [ 0.26444685, -0.23244599,  0.2348575 ,  0.0735738 , -0.17598692,\n",
       "          0.148951  , -0.15506388, -0.08207189],\n",
       "        [ 0.04724705, -0.00332627, -0.26281312, -0.20236772,  0.13218161,\n",
       "         -0.17948759,  0.17264152, -0.25954726],\n",
       "        [-0.16090243, -0.23228756, -0.04415955, -0.23396917, -0.17809325,\n",
       "          0.02209437,  0.15037328, -0.19621328],\n",
       "        [ 0.12079689,  0.11752155,  0.25582814, -0.25028136,  0.18598112,\n",
       "          0.20351648, -0.01980364,  0.26953846],\n",
       "        [ 0.05494094,  0.05203366,  0.20319557, -0.10551825,  0.14702052,\n",
       "          0.05823416, -0.17082334,  0.20374197],\n",
       "        [ 0.01574087,  0.05515718,  0.02908614,  0.02446947, -0.19487166,\n",
       "          0.2825215 , -0.17445286,  0.14802855],\n",
       "        [ 0.2397415 , -0.16901329, -0.21101373,  0.2060934 ,  0.02101946,\n",
       "         -0.25606573,  0.05736688, -0.1489601 ],\n",
       "        [-0.09530056,  0.2235601 , -0.17707773,  0.04534885, -0.11553931,\n",
       "         -0.15662594, -0.12367587,  0.07594085],\n",
       "        [-0.26709628, -0.08416472, -0.20656857, -0.2035478 , -0.03174466,\n",
       "         -0.08243486, -0.12686965, -0.02459568],\n",
       "        [-0.13914922,  0.01983511, -0.03411254,  0.09124219,  0.1900357 ,\n",
       "         -0.27286372,  0.11767635, -0.10280013],\n",
       "        [ 0.09011048, -0.07157227, -0.20847379,  0.16919294,  0.10493296,\n",
       "         -0.16926727, -0.14852354,  0.01239994],\n",
       "        [-0.17359102,  0.2688883 , -0.04888463,  0.06150749, -0.17945442,\n",
       "          0.2535057 , -0.13117227, -0.19243434],\n",
       "        [ 0.18736473,  0.18626943,  0.0567646 ,  0.00522682, -0.22437297,\n",
       "         -0.25649017,  0.03607151, -0.12362254],\n",
       "        [ 0.19662878,  0.14983624, -0.09461637,  0.12512794, -0.18999118,\n",
       "         -0.06993258, -0.12813583, -0.10810761],\n",
       "        [ 0.16118503, -0.01920554,  0.12022275, -0.27187964,  0.1883106 ,\n",
       "         -0.06446211, -0.16778973,  0.22279543],\n",
       "        [ 0.06870997,  0.24784416, -0.2573022 , -0.12787299, -0.01713887,\n",
       "         -0.23218122, -0.19640778, -0.24778362],\n",
       "        [ 0.22728795,  0.10060611,  0.08415896, -0.05929236,  0.19954741,\n",
       "         -0.05521265, -0.02771935,  0.09888464],\n",
       "        [-0.07071897, -0.1803534 ,  0.283275  ,  0.26135027, -0.24505056,\n",
       "          0.18797961, -0.20463306, -0.21216917],\n",
       "        [-0.01572257,  0.14289898, -0.23460265,  0.28302324, -0.16658589,\n",
       "         -0.25306764,  0.01693651, -0.0080885 ],\n",
       "        [-0.14175682, -0.19564685,  0.21228403,  0.05589312, -0.17678508,\n",
       "          0.1360293 , -0.24752808, -0.05017202],\n",
       "        [-0.14578098, -0.07086378, -0.09290943,  0.0185928 ,  0.05399299,\n",
       "          0.26647663,  0.0745385 ,  0.05275518],\n",
       "        [-0.22294153,  0.18161821,  0.0128462 , -0.08551556,  0.1913288 ,\n",
       "          0.20014638, -0.0386017 ,  0.00876549],\n",
       "        [-0.05837443,  0.05413863, -0.0080936 , -0.1392047 , -0.21072865,\n",
       "          0.06105587, -0.1083467 ,  0.18188739],\n",
       "        [-0.19617769,  0.11563671, -0.22845706,  0.03542677,  0.0471333 ,\n",
       "          0.14755881, -0.24845791, -0.06483535],\n",
       "        [ 0.17336142, -0.18316892,  0.00343391, -0.2460667 ,  0.2499854 ,\n",
       "         -0.02924168,  0.232212  , -0.08352754],\n",
       "        [ 0.15594238, -0.06698436, -0.19770384,  0.253309  , -0.07954784,\n",
       "         -0.07108878, -0.03502777, -0.04185081],\n",
       "        [-0.2288511 , -0.27919978, -0.21130465, -0.04214971, -0.24592663,\n",
       "         -0.14021808,  0.04275316, -0.05664243],\n",
       "        [-0.11432984, -0.11002323, -0.25871587, -0.24875571,  0.17358491,\n",
       "          0.00537631, -0.03757074,  0.12909883],\n",
       "        [ 0.12798145,  0.10912347,  0.07576823, -0.05759567, -0.15143856,\n",
       "          0.1764369 ,  0.22616816, -0.10736945],\n",
       "        [ 0.04827759,  0.20625913,  0.05137673, -0.18996763,  0.19363135,\n",
       "         -0.24579835, -0.04131988, -0.04882757],\n",
       "        [-0.03479517,  0.17246312, -0.2823703 , -0.19841039,  0.19907671,\n",
       "          0.19235954,  0.16013661,  0.06663865],\n",
       "        [ 0.0119203 ,  0.1687806 , -0.07500446,  0.06758371,  0.17413592,\n",
       "          0.27762157, -0.25151128, -0.23562229],\n",
       "        [ 0.20039484,  0.03447029, -0.10484156, -0.2720477 ,  0.00162393,\n",
       "          0.13990816, -0.24793386,  0.17743802],\n",
       "        [ 0.20433861, -0.2672041 ,  0.06397021, -0.07112402, -0.21013476,\n",
       "          0.09792233, -0.2578506 ,  0.1139228 ],\n",
       "        [ 0.12181056, -0.2884215 , -0.09134157, -0.26454854, -0.05672944,\n",
       "          0.09130731,  0.2615471 ,  0.12246332],\n",
       "        [-0.2764548 ,  0.1963565 ,  0.20349723, -0.27031112, -0.02564156,\n",
       "         -0.00897685,  0.12199584,  0.12803885],\n",
       "        [ 0.24889731, -0.24691167,  0.00621778,  0.07706901, -0.2786895 ,\n",
       "          0.03156662, -0.03147674, -0.06450479],\n",
       "        [ 0.1633394 , -0.27575913,  0.23802006, -0.10232696, -0.01413044,\n",
       "         -0.1085556 ,  0.05156085, -0.19094332],\n",
       "        [-0.14734799, -0.13472092,  0.12963349, -0.16645499, -0.00928733,\n",
       "         -0.28521308, -0.12267825,  0.11022818],\n",
       "        [ 0.02577722,  0.17864397, -0.19073063,  0.24533379,  0.12762761,\n",
       "          0.15024608,  0.19241342, -0.16651788],\n",
       "        [ 0.1000303 , -0.00638321, -0.10713284, -0.00962105, -0.2315905 ,\n",
       "          0.24706864, -0.27552423, -0.0586158 ],\n",
       "        [ 0.2542051 , -0.19132021, -0.18535998,  0.24178004, -0.22661027,\n",
       "         -0.2061225 , -0.18921083,  0.04414049],\n",
       "        [ 0.1590811 ,  0.02367136,  0.23807448, -0.23710003,  0.00606304,\n",
       "         -0.01469466, -0.00305194, -0.01395974],\n",
       "        [ 0.00375098,  0.15634838, -0.13360657, -0.24223113, -0.038899  ,\n",
       "         -0.22333452, -0.12513779, -0.08288443],\n",
       "        [-0.04370558, -0.02407867, -0.2855298 ,  0.25659168,  0.27943063,\n",
       "         -0.05027071,  0.21996057, -0.0854349 ],\n",
       "        [ 0.20192298, -0.1480359 , -0.2095606 , -0.04462536,  0.140991  ,\n",
       "         -0.04292455, -0.09163071, -0.26084167],\n",
       "        [-0.19397494, -0.09999645,  0.02920032, -0.09356643,  0.17967698,\n",
       "         -0.06719634, -0.17444006, -0.08175749],\n",
       "        [-0.01799786, -0.16137339,  0.04252246,  0.06313455,  0.18706396,\n",
       "          0.04575494,  0.2038633 ,  0.02763847]], dtype=float32)>,\n",
       " <tf.Variable 'dense_19/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_20/kernel:0' shape=(8, 1) dtype=float32, numpy=\n",
       " array([[-0.3993689 ],\n",
       "        [ 0.5526025 ],\n",
       "        [-0.5573065 ],\n",
       "        [ 0.16306615],\n",
       "        [-0.7175155 ],\n",
       "        [-0.5341693 ],\n",
       "        [-0.3442633 ],\n",
       "        [-0.6284592 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_20/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48095438],\n",
       "       [0.38764784],\n",
       "       [0.46399817],\n",
       "       [0.45152295],\n",
       "       [0.3950969 ],\n",
       "       [0.22237472],\n",
       "       [0.33510858],\n",
       "       [0.54572433],\n",
       "       [0.20901929],\n",
       "       [0.3356871 ]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4576 - accuracy: 0.7801\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4400 - accuracy: 0.7902\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4367 - accuracy: 0.7926\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4344 - accuracy: 0.7939\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4332 - accuracy: 0.7944\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4313 - accuracy: 0.7955\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4301 - accuracy: 0.7959\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4291 - accuracy: 0.7965\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4278 - accuracy: 0.7972\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4265 - accuracy: 0.7978\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4253 - accuracy: 0.7990\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4239 - accuracy: 0.7991\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4234 - accuracy: 0.7999\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4219 - accuracy: 0.8003\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4210 - accuracy: 0.8008\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4201 - accuracy: 0.8014\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4189 - accuracy: 0.8022\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4180 - accuracy: 0.8023\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4170 - accuracy: 0.8028\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4163 - accuracy: 0.8032\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4150 - accuracy: 0.8040\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4140 - accuracy: 0.8046\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4132 - accuracy: 0.8050\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4126 - accuracy: 0.8052\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4117 - accuracy: 0.8060\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4109 - accuracy: 0.8061\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4101 - accuracy: 0.8068\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4091 - accuracy: 0.8068\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4084 - accuracy: 0.8072\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4074 - accuracy: 0.8076\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4071 - accuracy: 0.8075\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4066 - accuracy: 0.8078\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4056 - accuracy: 0.8082\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4046 - accuracy: 0.8088\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4042 - accuracy: 0.8088\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4033 - accuracy: 0.8101\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4026 - accuracy: 0.8099\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4021 - accuracy: 0.8105\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4016 - accuracy: 0.8106\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4009 - accuracy: 0.8105\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3997 - accuracy: 0.8110\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3997 - accuracy: 0.8108\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3992 - accuracy: 0.8112\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3986 - accuracy: 0.8128\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3977 - accuracy: 0.8125\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3973 - accuracy: 0.8137\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3967 - accuracy: 0.8127\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3960 - accuracy: 0.8143\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3955 - accuracy: 0.8143\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3954 - accuracy: 0.8137\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3945 - accuracy: 0.8140\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3939 - accuracy: 0.8148\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3937 - accuracy: 0.8150\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3930 - accuracy: 0.8154\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3922 - accuracy: 0.8160\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3924 - accuracy: 0.8159\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3913 - accuracy: 0.8161\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3913 - accuracy: 0.8158\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3910 - accuracy: 0.8162\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3903 - accuracy: 0.8167\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3902 - accuracy: 0.8173\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3897 - accuracy: 0.8170\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3891 - accuracy: 0.8171\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3891 - accuracy: 0.8173\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3884 - accuracy: 0.8179\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3879 - accuracy: 0.8172\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3881 - accuracy: 0.8179\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3870 - accuracy: 0.8186\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3876 - accuracy: 0.8185\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3865 - accuracy: 0.8188\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3862 - accuracy: 0.8188\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3859 - accuracy: 0.8190\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3857 - accuracy: 0.8197\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3852 - accuracy: 0.8194\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3845 - accuracy: 0.8199\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3850 - accuracy: 0.8197\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3848 - accuracy: 0.8203\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3836 - accuracy: 0.8204\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3836 - accuracy: 0.8209\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3831 - accuracy: 0.8212\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3834 - accuracy: 0.8201\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3829 - accuracy: 0.8208\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3823 - accuracy: 0.8215\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8213\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8210\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8211\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3815 - accuracy: 0.8217\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3807 - accuracy: 0.8220\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3806 - accuracy: 0.8219\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3802 - accuracy: 0.8223\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3800 - accuracy: 0.8225\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3800 - accuracy: 0.8231\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3797 - accuracy: 0.8229\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3792 - accuracy: 0.8233\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3791 - accuracy: 0.8229\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3792 - accuracy: 0.8232\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3788 - accuracy: 0.8228\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3787 - accuracy: 0.8235\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3781 - accuracy: 0.8233\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3777 - accuracy: 0.8238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9b8030f6a0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x[:256000], y[:256000], epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4778 - accuracy: 0.7833\n",
      "Accuracy:  0.7833476662635803\n",
      "loss:  0.47781795263290405\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x[256000:512000], y[256000:512000])\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_18/kernel:0' shape=(600, 64) dtype=float32, numpy=\n",
       " array([[-0.86564416, -0.00440815,  0.15640804, ..., -0.08163399,\n",
       "         -0.48209044, -0.4300402 ],\n",
       "        [-0.88983804,  0.25214803,  0.3447045 , ..., -0.0623154 ,\n",
       "         -0.25372744, -0.5870787 ],\n",
       "        [-0.44380027,  0.12676288, -0.15944123, ...,  0.04876088,\n",
       "         -0.10257276, -0.46758392],\n",
       "        ...,\n",
       "        [ 0.31976184,  0.83458143,  0.71953225, ...,  0.4022435 ,\n",
       "          0.51563746,  0.5399129 ],\n",
       "        [ 0.41662648,  0.7033081 ,  0.69598955, ...,  0.38785124,\n",
       "          0.40374252,  0.561602  ],\n",
       "        [ 0.4242242 ,  0.69245523,  0.57545984, ...,  0.44767445,\n",
       "          0.4853984 ,  0.50967455]], dtype=float32)>,\n",
       " <tf.Variable 'dense_18/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-0.29801795, -1.6214861 , -0.97545475,  0.1046082 , -0.53778446,\n",
       "        -1.5176228 , -1.7269754 , -0.29097793, -1.160995  , -0.18192871,\n",
       "        -0.17721514, -0.52237654, -0.12061778, -0.44242588, -0.2944851 ,\n",
       "         0.10464574, -0.5684759 , -0.7735001 , -0.6510427 , -1.0946715 ,\n",
       "        -0.736701  , -0.42237917, -0.518951  , -0.47598362, -0.4354842 ,\n",
       "         0.02892896, -0.72210926, -0.00483659, -0.4316994 ,  0.43102616,\n",
       "        -1.2704868 , -0.30783793, -1.2089473 , -0.3622747 , -0.85673094,\n",
       "        -0.448762  , -0.3648317 , -0.66944575, -0.3263626 ,  0.01591664,\n",
       "        -0.9316867 , -0.328632  , -0.7901724 , -0.75840235, -0.25498143,\n",
       "        -0.34723878, -0.76866937,  0.31820208, -0.80147046, -0.795885  ,\n",
       "        -0.71767455, -0.6478372 , -0.8599956 , -0.53840375, -0.63257945,\n",
       "        -0.03746721, -0.21296076, -0.7806826 , -0.7137837 , -0.1209353 ,\n",
       "        -0.45066118, -0.6982215 , -0.35755572, -0.6077039 ], dtype=float32)>,\n",
       " <tf.Variable 'dense_19/kernel:0' shape=(64, 8) dtype=float32, numpy=\n",
       " array([[-1.59270570e-01, -2.08161160e-01, -7.51673758e-01,\n",
       "         -9.93737355e-02,  5.99401534e-01,  3.13000709e-01,\n",
       "          4.09495145e-01, -9.27129686e-02],\n",
       "        [-2.52712905e-01,  1.85038567e-01,  1.27123103e-01,\n",
       "          6.22134991e-02, -7.50040412e-01, -1.21677053e+00,\n",
       "         -1.80832550e-01,  4.07760948e-01],\n",
       "        [ 3.62426251e-01,  6.47303343e-01,  4.24176902e-01,\n",
       "         -2.04278260e-01, -9.83931303e-01, -8.60745311e-02,\n",
       "          4.51597244e-01, -1.52338427e-02],\n",
       "        [-1.20091513e-02,  3.79739553e-01, -1.33876488e-01,\n",
       "         -4.83897090e-01, -1.87608108e-01,  2.27969408e-01,\n",
       "         -9.97982621e-02, -4.65799630e-01],\n",
       "        [-1.01375914e+00, -9.76166055e-02, -1.32336903e+00,\n",
       "          6.86765984e-02,  8.25739861e-01,  3.60595763e-01,\n",
       "          3.55897576e-01, -1.13570344e+00],\n",
       "        [-1.81274079e-02, -2.44413033e-01, -2.02850163e-01,\n",
       "         -1.36174226e+00,  1.54659837e-01, -3.28749955e-01,\n",
       "          3.25003684e-01, -1.97790161e-01],\n",
       "        [-3.68616343e-01,  3.73213083e-01,  5.49318211e-05,\n",
       "          1.24854162e-01, -7.32588649e-01, -1.50269246e+00,\n",
       "         -9.71914008e-02,  9.17728662e-01],\n",
       "        [-1.31400734e-01,  5.80710769e-01,  1.79783791e-01,\n",
       "          1.84249774e-01,  4.10264552e-01,  2.24315196e-01,\n",
       "         -6.15399420e-01,  3.72352421e-01],\n",
       "        [ 6.27538189e-02,  2.42498536e-02,  3.78110945e-01,\n",
       "          1.92407414e-01, -1.69769526e+00, -5.59292912e-01,\n",
       "         -2.21773177e-01,  3.47343057e-01],\n",
       "        [-3.94859463e-01, -1.38484076e-01, -5.29571772e-01,\n",
       "          3.52815360e-01, -4.57740068e-01,  3.06193352e-01,\n",
       "         -1.03565788e+00,  1.61296576e-01],\n",
       "        [ 1.28048256e-01,  3.14957589e-01, -2.07437038e-01,\n",
       "          4.04607028e-01, -7.62916148e-01,  4.91641283e-01,\n",
       "          2.04203114e-01, -3.51555310e-02],\n",
       "        [-1.09659505e+00,  2.24303126e-01, -3.77292693e-01,\n",
       "         -2.19088957e-01, -8.67945373e-01, -1.42722964e-01,\n",
       "         -5.19934952e-01, -3.87905836e-02],\n",
       "        [ 1.31812934e-02,  2.29995161e-01,  1.03592195e-01,\n",
       "          5.75557530e-01,  2.12339628e-02, -8.21992755e-02,\n",
       "         -1.05015981e+00,  2.68479466e-01],\n",
       "        [ 5.96203990e-02, -5.59468210e-01, -3.33199382e-01,\n",
       "          1.33825555e-01,  3.35808963e-01, -1.23651791e-02,\n",
       "          1.34507731e-01, -1.06666908e-01],\n",
       "        [ 9.72242057e-02,  4.61286932e-01,  1.09150551e-01,\n",
       "         -8.94954652e-02,  3.85712832e-02, -2.07427502e-01,\n",
       "         -1.21842527e+00,  2.16794580e-01],\n",
       "        [-3.40245187e-01, -1.51916102e-01, -2.34070435e-01,\n",
       "         -6.50160134e-01,  8.44333172e-02, -1.17949061e-01,\n",
       "         -1.38689369e-01, -4.57844734e-01],\n",
       "        [-1.14448361e-01, -5.74280441e-01, -1.50213301e-01,\n",
       "         -1.69755947e-02, -2.74115771e-01,  6.69659451e-02,\n",
       "         -1.86644703e-01, -2.73082316e-01],\n",
       "        [-9.80844721e-02, -1.69827834e-01, -3.34072530e-01,\n",
       "         -5.16998231e-01,  2.25655869e-01, -3.55459780e-01,\n",
       "          3.34525913e-01, -7.81488419e-01],\n",
       "        [-2.67087430e-01, -3.69729787e-01, -1.72411829e-01,\n",
       "         -8.25470388e-01, -3.58822465e-01, -7.69935995e-02,\n",
       "          3.04696083e-01, -4.52938497e-01],\n",
       "        [ 2.90737301e-01,  6.06562383e-02,  6.31162882e-01,\n",
       "         -5.23704946e-01,  8.87479931e-02,  2.51858801e-01,\n",
       "         -1.18375257e-01,  7.59700835e-01],\n",
       "        [ 3.22694749e-01, -1.54725611e-01,  1.94474041e-01,\n",
       "         -9.14192125e-02,  4.40455407e-01,  2.75929064e-01,\n",
       "         -2.11135432e-01,  1.40262753e-01],\n",
       "        [-1.51123600e-02,  5.59340045e-03,  1.24052219e-01,\n",
       "          4.52764899e-01, -6.73207939e-02,  5.09344757e-01,\n",
       "          1.39148414e-01,  1.45874918e-01],\n",
       "        [ 4.11952525e-01, -4.03809339e-01, -6.95729733e-01,\n",
       "          1.96041703e-01, -6.38421476e-01, -4.90398973e-01,\n",
       "          3.06789204e-02, -1.73369214e-01],\n",
       "        [-9.27691534e-02, -6.96893840e-04,  1.26956433e-01,\n",
       "          3.66718620e-02, -8.02698076e-01, -4.47817504e-01,\n",
       "         -9.10077393e-01,  2.05709726e-01],\n",
       "        [-2.00658560e+00,  1.77832451e-02, -8.03285182e-01,\n",
       "         -1.08589768e-01, -1.91646919e-01, -1.31101876e-01,\n",
       "         -2.77625889e-01, -6.70062661e-01],\n",
       "        [-6.33889973e-01, -1.55980423e-01, -4.73028302e-01,\n",
       "          4.69273895e-01,  2.41005704e-01, -1.64684266e-01,\n",
       "          2.60659337e-01,  2.95715239e-02],\n",
       "        [ 4.63316411e-01,  1.17766865e-01, -5.55341542e-01,\n",
       "          1.19782291e-01,  1.36810645e-01, -7.75951624e-01,\n",
       "         -1.50718153e-01,  1.37233242e-01],\n",
       "        [-1.18372691e+00,  1.71500534e-01, -9.92510617e-01,\n",
       "         -5.28153032e-02, -7.52433777e-01,  1.31227687e-01,\n",
       "         -4.65498120e-02, -1.20200932e+00],\n",
       "        [-9.67780203e-02,  1.20960008e-02, -8.89513433e-01,\n",
       "         -8.20318013e-02, -1.37376487e+00, -2.84417361e-01,\n",
       "         -4.45274115e-02,  1.68962032e-01],\n",
       "        [ 2.05176830e-01,  1.36755303e-01, -1.43992797e-01,\n",
       "          2.68688470e-01, -2.63100505e-01, -1.59445331e-01,\n",
       "         -1.14178061e-01, -2.23219454e-01],\n",
       "        [ 2.57654458e-01,  3.18584236e-04,  1.46797076e-01,\n",
       "         -3.72358233e-01,  1.21351974e-02, -4.66613114e-01,\n",
       "          3.57318789e-01,  2.23655462e-01],\n",
       "        [-3.65243375e-01,  1.52679563e-01, -1.40615594e+00,\n",
       "         -3.20336133e-01, -1.11257529e+00, -1.30842268e-01,\n",
       "         -9.58394527e-01, -3.69210601e-01],\n",
       "        [ 6.05282366e-01,  6.99979484e-01,  4.02293392e-02,\n",
       "          1.35145992e-01,  3.45826238e-01,  7.76017532e-02,\n",
       "          2.41347685e-01,  2.07691312e-01],\n",
       "        [ 1.70449793e-01, -3.36366236e-01,  6.83354735e-01,\n",
       "          4.12724644e-01, -4.37437713e-01,  1.45649314e-01,\n",
       "         -3.64444345e-01, -4.91267771e-01],\n",
       "        [ 4.75851260e-02,  2.66071409e-02, -8.75906125e-02,\n",
       "          6.04154527e-01, -2.06554413e-01, -2.97932595e-01,\n",
       "         -9.12794888e-01,  3.59279990e-01],\n",
       "        [ 5.58076859e-01, -2.78600007e-01,  9.92468357e-01,\n",
       "          2.64515787e-01, -7.38933146e-01,  1.76494375e-01,\n",
       "          7.08204433e-02,  3.43227118e-01],\n",
       "        [-4.83295113e-01,  4.78199273e-01, -6.62055135e-01,\n",
       "          5.12068868e-01,  2.86932617e-01,  7.12132037e-01,\n",
       "          4.76538718e-01,  1.88147292e-01],\n",
       "        [-3.31677347e-02,  8.21794927e-01,  5.65187514e-01,\n",
       "         -2.14393705e-01,  5.94343126e-01,  5.25540411e-01,\n",
       "          4.63719785e-01,  2.62582898e-01],\n",
       "        [-2.93743402e-01,  2.72377133e-01,  5.35273030e-02,\n",
       "         -2.86856681e-01, -7.14276135e-01,  5.17865419e-01,\n",
       "          2.76581734e-01,  4.78076413e-02],\n",
       "        [-2.46914729e-01,  3.15526247e-01, -5.46931982e-01,\n",
       "          2.11505979e-01, -8.06556568e-02,  3.66393864e-01,\n",
       "         -1.14730835e-01, -1.01354927e-01],\n",
       "        [-3.44549865e-02, -4.63569582e-01,  3.64271671e-01,\n",
       "         -9.43271279e-01,  4.71225619e-01, -1.38171464e-01,\n",
       "          7.05003887e-02, -1.29535899e-01],\n",
       "        [ 4.66524392e-01, -1.24694291e-03, -6.64413691e-01,\n",
       "          4.83025342e-01, -3.27454537e-01, -2.11837262e-01,\n",
       "          8.15100372e-02, -5.88773131e-01],\n",
       "        [-7.02966273e-01, -3.36031616e-01, -3.30498628e-03,\n",
       "          7.27238832e-03, -2.05575868e-01,  3.54146063e-01,\n",
       "          3.27194110e-02, -9.70714629e-01],\n",
       "        [-5.32480597e-01, -2.07034320e-01, -4.51886952e-01,\n",
       "         -3.19869906e-01,  2.67570943e-01,  2.82033056e-01,\n",
       "         -3.10911626e-01, -1.85022634e-02],\n",
       "        [ 9.73210260e-02,  5.13678849e-01,  3.26486409e-01,\n",
       "         -2.96420783e-01, -2.50819236e-01,  2.31669486e-01,\n",
       "          3.32768774e-04, -4.61677343e-01],\n",
       "        [ 5.15520424e-02,  1.52535930e-01,  3.65993023e-01,\n",
       "         -2.49306932e-01,  3.91198918e-02, -5.28899312e-01,\n",
       "         -1.34339586e-01,  1.38955846e-01],\n",
       "        [ 2.43502125e-01,  6.76070511e-01, -9.19784069e-01,\n",
       "         -9.54668462e-01,  7.49908090e-02,  3.15471441e-01,\n",
       "          2.08045095e-01,  1.02320038e-01],\n",
       "        [-2.76717804e-02,  1.98193789e-01,  1.17496356e-01,\n",
       "         -1.02779798e-01,  1.12036385e-01,  2.28114471e-01,\n",
       "         -3.51384163e-01, -4.65594798e-01],\n",
       "        [ 6.97940961e-02,  3.98492813e-01, -2.31720269e-01,\n",
       "         -8.61803889e-01,  2.61391312e-01,  3.78203660e-01,\n",
       "         -6.78241551e-01,  2.52089538e-02],\n",
       "        [-4.18665819e-02, -3.54606062e-01,  8.76769349e-02,\n",
       "          2.97082812e-01, -8.04348648e-01,  9.85863954e-02,\n",
       "         -8.22494090e-01, -2.82690283e-02],\n",
       "        [ 2.10627452e-01, -4.87740248e-01,  2.46339366e-01,\n",
       "         -1.27550691e-01, -8.82498384e-01, -5.01537602e-03,\n",
       "          3.05165589e-01,  7.61741027e-02],\n",
       "        [-6.60856843e-01,  2.81733423e-01,  7.30950758e-02,\n",
       "         -1.03754854e+00, -5.59472263e-01,  1.49445549e-01,\n",
       "         -1.18784212e-01, -4.51521501e-02],\n",
       "        [ 4.27554578e-01, -2.17017189e-01,  1.59843802e-01,\n",
       "         -2.22321689e-01, -2.66815811e-01,  3.12741905e-01,\n",
       "         -6.57132119e-02, -1.46937871e+00],\n",
       "        [ 7.16001213e-01, -5.16146779e-01,  8.14417183e-01,\n",
       "         -1.23449050e-01,  6.07689857e-01,  5.52035391e-01,\n",
       "          1.81259006e-01, -2.49721065e-01],\n",
       "        [-2.64185578e-01, -4.91082042e-01,  1.67288065e-01,\n",
       "         -9.04068351e-02, -3.33952010e-01, -5.97897768e-01,\n",
       "          1.18023433e-01, -6.88744616e-03],\n",
       "        [ 2.89046228e-01,  2.37138376e-01, -1.93987787e-01,\n",
       "          5.87878406e-01,  6.78531155e-02, -1.43224960e-02,\n",
       "          1.02632388e-01, -1.41582429e-01],\n",
       "        [-1.04706693e+00, -8.67205203e-01, -1.66262940e-01,\n",
       "          3.53865698e-02,  4.85999554e-01,  1.10705721e+00,\n",
       "          2.39336804e-01, -2.72605211e-01],\n",
       "        [ 3.94127578e-01, -3.26767445e-01, -1.54611617e-01,\n",
       "          3.75336170e-01, -3.46643537e-01, -6.08935878e-02,\n",
       "         -1.19031608e+00,  7.59806186e-02],\n",
       "        [ 2.32784435e-01,  1.13687545e-01,  1.99148536e-01,\n",
       "         -1.11657035e+00,  7.67746866e-02, -5.64773008e-02,\n",
       "         -7.40531161e-02, -7.95190856e-02],\n",
       "        [-1.25555634e-01,  1.91085726e-01, -1.63224268e+00,\n",
       "         -1.10236786e-01, -2.70491004e-01, -1.10818096e-01,\n",
       "         -1.03748906e+00, -1.34352112e+00],\n",
       "        [-4.71936315e-01,  4.51191776e-02, -8.94196868e-01,\n",
       "          8.01131129e-01,  2.17035085e-01, -2.52043575e-01,\n",
       "          2.55895048e-01,  3.69337499e-02],\n",
       "        [ 1.09017980e+00,  1.37868598e-01, -4.39026743e-01,\n",
       "         -5.19415783e-03,  6.21102631e-01,  4.36814465e-02,\n",
       "         -3.81722987e-01, -1.50949860e+00],\n",
       "        [-1.10337615e+00, -3.34628463e-01,  3.73393029e-01,\n",
       "         -1.51884988e-01,  2.13315755e-01, -3.07735503e-01,\n",
       "         -2.27709375e-02, -9.13083494e-01],\n",
       "        [-7.64584318e-02, -6.70681179e-01,  3.29946518e-01,\n",
       "          8.12706538e-03,  3.07725251e-01, -1.74496949e-01,\n",
       "          4.83636379e-01, -1.64186910e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_19/bias:0' shape=(8,) dtype=float32, numpy=\n",
       " array([-0.13544047,  0.2000588 , -0.21682377,  0.41392514, -0.14630929,\n",
       "        -0.0524788 ,  0.29183596, -0.8341665 ], dtype=float32)>,\n",
       " <tf.Variable 'dense_20/kernel:0' shape=(8, 1) dtype=float32, numpy=\n",
       " array([[-0.43203104],\n",
       "        [ 0.2597903 ],\n",
       "        [-0.7015743 ],\n",
       "        [ 0.20216954],\n",
       "        [-2.4704602 ],\n",
       "        [-0.36432496],\n",
       "        [-1.1999956 ],\n",
       "        [-0.6644999 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_20/bias:0' shape=(1,) dtype=float32, numpy=array([-0.27484557], dtype=float32)>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
